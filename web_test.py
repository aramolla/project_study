from langchain_openai import OpenAIEmbeddings, ChatOpenAI
import os
import streamlit as st

# Set up page configuration
st.set_page_config(
    page_title="ìƒëª…ëŒ€í•™êµ Chatbot", 
    page_icon="./ìˆ˜ë­‰1.png",  # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    layout="wide"
)
st.title("AI ìˆ˜ë­‰ ğŸ’¬")

# CSS to inject contained in a string
custom_css = """
            <style>
            /* Hide Streamlit style elements */
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}

            /* General page background */
            body {
                background-color: #f5f5f5;
                color: #333333;
            }

            /* Sidebar customization */
            .css-1d391kg {
                background-color: #ffffff !important;
                border-right: 1px solid #e0e0e0;
            }

            /* Input field styling */
            .stTextInput>div>div>div>input {
                padding: 10px 20px;
                border-radius: 10px;
                border: 1px solid #ccc;
                background-color: #ffffff;
                color: #333333;
            }

            /* Button styling */
            .stButton>button {
                border-radius: 10px;
                padding: 10px 20px;
                border: none;
                background-color: #007bff;
                color: #ffffff;
                font-weight: bold;
            }
            .stButton>button:hover {
                background-color: #0056b3;
                color: #ffffff;
            }

            /* Chat message styling */
            .stChatMessage {
                border: 1px solid #e0e0e0;
                border-radius: 10px;
                padding: 10px;
                color: #000000; /* í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ê²€ì •ìœ¼ë¡œ ë³€ê²½ */
                margin: 10px 0;
                max-width: 60%; /* ê°€ë¡œ ê³µê°„ì˜ 60%ë§Œ ì°¨ì§€ */
                display: flex;
                align-items: center;
            }

            .stChatMessage-user {
                background-color: #e9ecef;
                color: #000000; /* í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ê²€ì •ìœ¼ë¡œ ë³€ê²½ */
                text-align: right; /* í…ìŠ¤íŠ¸ ì˜¤ë¥¸ìª½ ì •ë ¬ */
                margin-left: auto; /* ì™¼ìª½ ë§ˆì§„ì„ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì˜¤ë¥¸ìª½ ì •ë ¬ */
                justify-content: flex-end; /* ì½˜í…ì¸ ë¥¼ ì˜¤ë¥¸ìª½ ì •ë ¬ */
            }

            .stChatMessage-assistant {
                background-color: #f8f9fa;
                color: #000000; /* í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ê²€ì •ìœ¼ë¡œ ë³€ê²½ */
                text-align: left; /* í…ìŠ¤íŠ¸ ì™¼ìª½ ì •ë ¬ */
                margin-right: auto; /* ì˜¤ë¥¸ìª½ ë§ˆì§„ì„ ìë™ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì™¼ìª½ ì •ë ¬ */
                justify-content: flex-start; /* ì½˜í…ì¸ ë¥¼ ì™¼ìª½ ì •ë ¬ */
            }


            </style>
            """
st.markdown(custom_css, unsafe_allow_html=True)

# OpenAI API Key ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# í˜ì´ì§€ê°€ ì„¸ë¡œê³ ì¹¨ì´ ì¼ì–´ë‚˜ë„ ì´ì „ ë©”ì‹œì§€ê°€ ìŒ“ì´ë„ë¡ ë°ì´í„° ë³´ê´€
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# ì±„íŒ… ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ëŠ” Store ì„¸ì…˜ ìƒíƒœ ë³€ìˆ˜
if "store" not in st.session_state:
    st.session_state["store"] = dict()

menu = st.sidebar.selectbox("ë©”ë‰´", ["ë©”ì¸ í˜ì´ì§€", "ì£¼ê°„ ë©”ë‰´"])

if menu == "ë©”ì¸ í˜ì´ì§€":
    pass
elif menu == "ì£¼ê°„ ë©”ë‰´":
    if st.button("ì´ë¯¸ì§€ íŒì—…"):
        with st.modal("ì´ë¯¸ì§€ íŒì—…"):
            st.image("./menu.jpg", width=200)
            
with st.sidebar:    
    st.image("./ìˆ˜ë­‰_2.png", width=200)

    session_id = st.text_input("Session ID", value="ara123")
    clear_btn = st.button("ì´ˆê¸°í™”")
    if clear_btn:
        st.session_state["messages"] = []
        if session_id in st.session_state["store"]:
            del st.session_state["store"][session_id]  # íŠ¹ì • ì„¸ì…˜ IDì— ëŒ€í•œ ê¸°ë¡ë§Œ ì‚­ì œ
        st.experimental_rerun()


from utils import print_messages, StreamHandler

print_messages()  # ì´ì „ ëŒ€í™”ë‚´ìš© ì¶œë ¥

from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory

# ì„¸ì…˜ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
def get_session_history(session_id: str) -> BaseChatMessageHistory:
    if session_id not in st.session_state["store"]:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°
        st.session_state["store"][session_id] = ChatMessageHistory()  # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ Storeì— ì €ì¥
    return st.session_state["store"][session_id]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜

from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.base import RunnableSequence, RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory

if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."):
    st.session_state["messages"].append(("user", user_input))
    st.chat_message("user").write(f"{user_input}")

    with st.chat_message("assistant"):
        container = st.empty()
        stream_handler = StreamHandler(container)

        # ëª¨ë¸ ìƒì„±  gpt-3.5-turbo-1106 gpt-4o-2024-05-13
        GPT_4o = ChatOpenAI(model="gpt-4o-2024-05-13", streaming=True, callbacks=[stream_handler])
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")

        # ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
        def load_vector_store(path):
            return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)

        vector_store_path = "./merged_vector_store"
        db = load_vector_store(vector_store_path)

        retriever = db.as_retriever(
            search_type="similarity",
            search_kwargs={'k': 50}
        )







        # from langchain.schema import Document
        # from langchain_community.vectorstores import Chroma
        # from langchain.retrievers.self_query.base import SelfQueryRetriever

        # document_content_description = "í•™êµ í™ˆí˜ì´ì§€ ì •ë³´"

        # retriever = SelfQueryRetriever.from_llm(
        #     GPT_4o,
        #     db,
        #     document_content_description,
        #     metadata_field_info,
        #     verbose = True
        # )








        prompt_template = """
        ### [INST]
        AIìˆ˜ë­‰ì…ë‹ˆë‹¤! ê¶ê¸ˆí•œê±¸ ë¬¼ì–´ë³´ì‡¼

        {context}

        ### ì§ˆë¬¸:
        {question}

        [/INST]
        ë‹µë³€!
        """

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = ChatPromptTemplate.from_messages(
            [
                ("system", 
                    """
                    ì—­í• : ë„ˆëŠ” ë°˜ë§ë¡œ ë‹µë³€í•˜ëŠ” ìƒëª…ëŒ€í•™êµ í•™ìƒë“¤ì˜ í•™êµ ìƒí™œì„ ë„ì™€ì¤„ ë„ìš°ë¯¸ì•¼. ìƒëª…ëŒ€í•™êµë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” ë°˜ë“œì‹œ "ìš°ë¦¬ í•™êµ"ë¼ê³  ì§€ì¹­í•´ì¤˜.
                    ì´ë¦„: ë„ˆì˜ ì´ë¦„ì€ 'ìˆ˜ë­‰'ì´ì•¼.
                    ì‚¬ìš©ì í˜¸ì¹­: ë„ˆê°€ userë¥¼ ë¶€ë¥¼ ë•ŒëŠ” 'ìŠ´ìš°'ë¼ê³  ë¶ˆëŸ¬ì•¼ ë¼.
                    """
                ),
                MessagesPlaceholder(variable_name="history"),
                ("human", prompt_template.format(context="{context}", question="{question}")),
            ]
        )

        # LLM ì²´ì¸ ìƒì„±
        llm_chain = prompt | GPT_4o

        # rag_chain ì •ì˜ ìˆ˜ì •
        rag_chain = RunnableSequence(
            RunnableLambda(lambda x: {
                "context": [doc.page_content for doc in retriever.get_relevant_documents(x["question"])],
                "question": x["question"],
                "history": x["history"]  # ì¶”ê°€ëœ ë¶€ë¶„
            }),
            llm_chain
        )

        chain_with_memory = RunnableWithMessageHistory(
            rag_chain,
            lambda session_id: get_session_history(session_id),
            input_messages_key="question",
            history_messages_key="history",
        )

        # chain_with_memory.invoke í˜¸ì¶œ ë¶€ë¶„ ìˆ˜ì •
        response = chain_with_memory.invoke(
            {"question": user_input, "history": []},  # history ì¶”ê°€
            config={'configurable': {'session_id': session_id}}
        )


        # for i in response['context']:
        #     print(f"ì£¼ì–´ì§„ ê·¼ê±°: {i.page_content} / ì¶œì²˜: {i.metadata['source']} - {i.metadata['page']} \n\n")


        msg = response.content  # ì†ì„±ìœ¼ë¡œ ì ‘ê·¼

        # st.write(msg)
        st.session_state["messages"].append(("assistant", msg))

        
     
