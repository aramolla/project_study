### RAG 시스템, 랭체인

#### 챗지피티의 문제점
1. 정보 접근 제한 : 학습된 이후인 최신 정보일 경우 거짓된 답변 제공
2. 토큰 제한 : 3.5(4096), 4(8192)
3. 환각현상 : 정보가 없는데 아는척하는 경우가 많음

#### 랭체인을 이용
1. Fine-tuning : 기존 딥러닝 모델의 weight를 조정해서 원하는 용도의 모델로 업데이트
	-> 모델을 다시 한번 학습시킴. 그래픽카드,시간,비용들 많이 소요
2. N-shot learning : 0~n개의 출력 예시를 제시하여, 딥러닝이 용도에 알맞은 출력을 하게함
	->우리가 어떤 정보를 주고 그 정보를 기반으로 대답하라 할 수는 없음
3. In-context learning : 문맥을 제시하고, 문맥기반으로 모델이 출력하게 조정
	-> 어떤 한 분야의 전문적인 지식을 가지게 하고 싶을 때 적합

#### 문제 해결 방안
1. 정보접근제한->vectorstore기반 정보탐색 또는 Agent활용한 검색 결합으로 좀 더 다양한 정보에 접근해서 대답
2. 토큰제한->testsplitter를 활용해 문서 분할하여 문서를 요약하고 답변 정리해서 대답
3. 환갹현상->주어진 문서로만 답하게 하도록 Prompt입력

#### 랭체인의 구조
LLM
Prompts: LLM에게 지시하는 명령문, 
	Chat prompt template : 채팅모델인 경우 프롬프트 템플렛으로 대화를 매끄럽게  할 수 있음. 
	example Selector: n샷 러닝과 같이 원하는 출력형식을 예시들을 통해서 이해시킬때, 어떤 예시를 선택하여 LLM학습을 시킬지 자동으로 랭체인을 구동시킬 수 있다
	output parsers : 랭체인을 통해서 원하는 형식으로 답변하게 해줌
		(오늘의 날씨는 맑습니다->맑음)
Index: LLM이 문서를 쉽게 탘색할 수 있게 도와주는 모듈(document loaders, text splitters, vector stores, retrievers,…)
Memory: 이전 출력한 내용(답변한 내용)을 기억하고 이응 기반으로 대화
Chain: LLm사슬을 형성해서 연속적인 LLM호출이 가능하도록 하는 핵십요소
	(프롬프트를 하나 주면 랭체인이 뒷단에서 그 프롬프트를 받아서 다시 프롬프트를 만들고 그 뒤 체인에도 프롬프트를 만드는 형식 )
	(사슬처럼 프롬프트들이 연결이 되어 원하는 퀄리티를 얻을 수 있게끔 함)
		(llm chain, 
		question answering- 원하는 정보 물어볼때 간단히 불어보더라도 특정정보를 기반으로 잘 대답할 수 있는지 프롬프트 템플렛이 들어가있다
		Summarization-요약 가능 
		retrieval Question/Answering-어떤 소스를 기반으로 이 답변을 하는지 구동 가능)
Agents: prompt template으로 수행할 수 없는 작업을 가능케하는 모듈
	(에이전트가 중요하기보단 에이전트에 들어가는 툴들이 중요(웹 검색, 쿼리를 작성하여 정보를 빼내기)등 여러가지 툴들을 LLM이 자체적으로 판단해서 구동하게끔 만드는것이 에이전트)

#### pdf챗봇 구축 과정

<img width="496" alt="스크린샷 2024-05-05 오후 8 48 19" src="https://github.com/aramolla/project_study/assets/105141243/cc2ccb51-b7b8-4c99-95f6-c64a30d505a4">


RAG(Retrieval-Augmented Generation)는 자연어 처리(NLP)에서 사용되는 기술로, 기계학습 모델이 텍스트 생성을 할 때 관련 정보를 검색하여 결과를 향상시키는 방법

RAG 기법

	•	Multi-query : 질문에서 여러개의 유사질문 생성	
	이거 어때? 이런식으로 대충 질문해도 좋다/아니다 이런식으로가 아니라 그 질문안에서 스스로 다방면의 질문들을 생성해서 답하는거
		ex) 	Q. 은행대출
				A. 좋다 -> 금리는…, 조건은…, 후기는…. 


	•	parent-Document : 앞뒤 문맥담기
 
<img width="627" alt="스크린샷 2024-05-05 오전 11 20 51" src="https://github.com/aramolla/project_study/assets/105141243/7cc6d49a-f4aa-466b-9c19-a237f8d1e40b">

	기존 레그시스템: 질문들어옴->유사청크를 백터스토어안에서 찾음->LLM에 넘겨주고 답변을 받음
  	  	문제=>대부분의 내용이 1-1에 포함, 매우 소수의 문장이지만 핵심인 내용이 1-2에 포함되어있는 경우
	Parent-document 시스템: 1-1을 포함하고 있는 parent-document를LLM에 전달
	(1-1을 포함한 문서를 모두 참고하기때문에 1-1의 앞뒤맥락을 모두 포함)



	•	Self-querying : 문서의 메타데이터를 기반으로 필터링 생성
  	
	일반적인 경우
<img width="290" alt="스크린샷 2024-05-05 오전 11 22 56" src="https://github.com/aramolla/project_study/assets/105141243/f3b5d71b-cfdf-4d4b-8ec9-247085329140">

	문제점!!
		질문자가 원하는건 평점 9점 이상인 영화라는 문장이 유사한 텍스트를 찾는게 목적x
		=> 이 정보가 담긴 DB에서 평점9점이상인 영화로 필터링 후, sf장르로 필터링하는 과정이 필요
			(기본적인 RAG시스템이 아니라 Query하는 시스템이 필요)


 	Self-querying 리트리버
<img width="280" alt="스크린샷 2024-05-05 오전 11 23 40" src="https://github.com/aramolla/project_study/assets/105141243/9c14a6cb-cdf8-41c5-9049-3a2e7ade3ea6">

	사용자의 질문을 기반으로 문서의 메타데이터를 필터링하는 식이 생성
		(유의: 필터링하는 작업이 필요한 질문에 적합한 리트리버)



	•	Time-Weieghted : 가장 최근에 이용된 문서기준으로 먼저 참고하여 답변의 Freshness유지
	
	질문: 평점이 9점 이상인 영화 중에 sf영화 추천해줘 -> “최신 영화 중”+평점 9 이상+sf영화
		=>시간이 지난 문서인 만큼 패널티를 주자
		
		공식: 시멘틱 시밀러리티+(1.0-decay_rate)^경과한 시간
			decay_rate=1 시간 신경 노
			decay_rate=0 시간 신경써

리트리버 종류
	-sparse 
		문서: 각 단어가 문서에 몇번씩 나왔는지 행렬로 저장-> 이걸로 인덱스를 만들어서 사용자의 질문와 유사한 참고문서로 내놓음
			(흠 일단 맞는 단어 찾고 질문이랑 비슷한 단어 많으면 그거 내놓는 방식인가)
   <img width="233" alt="스크린샷 2024-05-05 오전 11 24 10" src="https://github.com/aramolla/project_study/assets/105141243/e5b80a37-0f7a-4bd6-bb7a-b30321954458">

		장: 빠르고 간편 out of domain검색 유리 뭔지 모름
		단:이음동의어 처리, 맥락 이해 X

	-dense
		문서: 인코더 딥러닝모델에 통과->정해진 차원 내에서 밀집된백터 -> 인덱스로 저장 
		질문: 인코더->밀집 백터
		=> 문서-질문 밀집 백터간의 유사도를 비교하여 리트리버 구성
￼<img width="229" alt="스크린샷 2024-05-05 오전 11 24 17" src="https://github.com/aramolla/project_study/assets/105141243/dc1414c2-f666-47b3-8818-f0fb5762008d">

		장: 맥락을 고려해서 검색품질 굿, 이은동의어 가능
		단:종종 키워드 포함안함(인코더가 가진 사전 학습 기반으로 유사도를 비교하기 때문)

	지금까지 내가 한게(FAISS) dense 리트리버인데 이러면 tmi도 심해짐
	Ex)비타민B1이 뭐야?-B1,2,3 다 알려줌
	그래서 sparse랑 혼합함-> 앙상블 리트리버

	앙상블리트리버엔 Reciprocal Rank Fusion도 있다
	그ㅔ뭐게- BM25(스팔스)의 키워드 + FAISS(덴스)맥락으로 나온 결과 -> 참고순위 재정렬해주는거임!
		Ex)비타민B1의 장점 알려줘
			1. 비타민B1이란                                      1. 비타민B1의 장점은
			2. 비타민B1의 장점은            -------->             2. 비타민B1이란
			3. 비타민B1의 단점은     (Reciprocal Rank Fusion)     3. 비타민B1의 단점은

